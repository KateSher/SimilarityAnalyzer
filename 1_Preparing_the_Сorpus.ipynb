{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_Preparing_the_Сorpus.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMGnEKKPTtOWqVMQbw2lF/b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Loading the required libraries"],"metadata":{"id":"xuuZ9bed-yUu"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pZSu-6Cltd1b"},"outputs":[],"source":["import logging\n","import smart_open\n","from gensim.corpora.wikicorpus import WikiCorpus, tokenize"]},{"cell_type":"code","source":["# Google drive mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ayanH32Gtsjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0e3a23ce"},"outputs":[],"source":["logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"]},{"cell_type":"markdown","source":["## Preparing the corpus"],"metadata":{"id":"E8tx23dwb5rK"}},{"cell_type":"markdown","source":["The notebook used a dump that was actual as of 06/21/2022. To train a new model, necessary to download the actual dump of Wikipedia from [here](https://dumps.wikimedia.org/enwiki/)."],"metadata":{"id":"jlBHjJcna_SU"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"050f093e","executionInfo":{"status":"ok","timestamp":1655822928847,"user_tz":-180,"elapsed":114037,"user":{"displayName":"Kateryna Sheremet","userId":"03402668552086225828"}},"outputId":"840b71db-f686-4965-8e59-0307f5dde4b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-06-21 14:46:54--  https://dumps.wikimedia.org/enwiki/20220320/enwiki-20220320-pages-articles-multistream9.xml-p2936261p4045402.bz2\n","Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.7, 2620:0:861:1:208:80:154:7\n","Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.7|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 555343728 (530M) [application/octet-stream]\n","Saving to: ‘enwiki-20220320-pages-articles-multistream9.xml-p2936261p4045402.bz2’\n","\n","enwiki-20220320-pag 100%[===================>] 529.62M  4.58MB/s    in 1m 54s  \n","\n","2022-06-21 14:48:48 (4.66 MB/s) - ‘enwiki-20220320-pages-articles-multistream9.xml-p2936261p4045402.bz2’ saved [555343728/555343728]\n","\n"]}],"source":["!wget https://dumps.wikimedia.org/enwiki/20220320/enwiki-20220320-pages-articles-multistream9.xml-p2936261p4045402.bz2"]},{"cell_type":"markdown","source":["Converted Wikipedia article dump from Wikimedia XML format into a text file. Preprocessed each article at the same time, normalizing its text to lowercase, splitting into tokens. "],"metadata":{"id":"6uCx7oRtkXdG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"085a28f5","outputId":"9543de8c-ed26-4484-b6d4-c467b69b89a2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655824222193,"user_tz":-180,"elapsed":1293351,"user":{"displayName":"Kateryna Sheremet","userId":"03402668552086225828"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["2022-06-21 14:48:48,477 : INFO : processing article #0: 'David Stagg' (326 tokens)\n","2022-06-21 15:10:21,485 : INFO : finished iterating over Wikipedia corpus of 153429 documents with 110468270 positions (total 415310 articles, 111511108 positions before pruning articles shorter than 50 words)\n"]}],"source":["wiki = WikiCorpus(\n","    \"enwiki-20220320-pages-articles-multistream9.xml-p2936261p4045402.bz2\",  # path to the file you downloaded above\n","    tokenizer_func=tokenize,  # simple regexp; plug in your own tokenizer here\n","    dictionary={},  # don't start processing the data yet\n",")\n","wiki.metadata = True\n","\n","with smart_open.open(\"drive/MyDrive/Colab Notebooks/wiki.txt.gz\", \"w\", encoding='utf8') as fout:\n","    for article_no, (content, (page_id, title)) in enumerate(wiki.get_texts()):\n","        title = ' '.join(title.split())\n","        if article_no % 500000 == 0:\n","            logging.info(\"processing article #%i: %r (%i tokens)\", article_no, title, len(content))\n","        fout.write(f\"{title}\\t{' '.join(content)}\\n\")  # title_of_article [TAB] words of the article"]}]}